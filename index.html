<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Rolling Sink: Bridging Limited-Horizon Training and Open-Ended Testing in Autoregressive Video Diffusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Rolling Sink</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-1FWSVCGZTG"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-1FWSVCGZTG');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="./css/twentytwenty.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="icon" href="./images/lotus_icon.png">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <script src="./js/jquery-3.2.1.min.js"></script>
  <script src="./js/jquery.event.move.js"></script>
  <script src="./js/jquery.twentytwenty.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/fontawesome.all.min.js"></script>

  <!--MathJax-->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<style>
  .rolling-sink{
    display: inline-block;
    line-height: 1.3;
    background: linear-gradient(
      90deg,
      #0095ff 0%,
      #dd51cd 50%,
      #0095ff 100%
    );
    -webkit-background-clip: text; background-clip: text;
    color: transparent;
  }
  .rolling-sink-2{
    display: inline-block;
    /* line-height: 1.2; */
    background: linear-gradient(
      90deg,
      #0095ff 0%,
      #dd51cd 50%,
      #0095ff 100%
    );
    -webkit-background-clip: text; background-clip: text;
    color: transparent;
    -webkit-text-fill-color: transparent;
  }
</style>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title rolling-sink" style="font-size: 2.8rem;">Rolling Sink</h1>
          <h1 class="title is-1 publication-title" style="font-size: 2.0rem; margin-top: -20px;">Bridging <u>Limited-Horizon</u> Training and <u>Open-Ended</u> Testing in Autoregressive Video Diffusion</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://haodong2000.github.io/" target="_blank" rel="noopener noreferrer">
                Haodong Li<sup>1</sup>
            </a>
            </span>
            <span class="author-block">
              <a href="https://www.shaotengliu.com/" target="_blank" rel="noopener noreferrer">
                Shaoteng Liu<sup>2</sup>
            </a>
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/site/zhelin625/" target="_blank" rel="noopener noreferrer">
                Zhe Lin<sup>2</sup>
            </a>
            </span>
            <span class="author-block">
                <a href="https://cseweb.ucsd.edu/~mkchandraker/" target="_blank" rel="noopener noreferrer">
                Manmohan Chandraker<sup>1</sup><sup style="font-size: 1.3rem;">&#9993;</sup></a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>UC San Diego</span>
            <span class="author-block"><sup>2</sup>Adobe Research</span>
            <span class="author-block">
                <!-- <strong>*</strong>Equal contribution. -->
                <sup style="font-size: 1.3rem;">&#9993;</sup>Corresponding author
            </span>
            <br>
            <span class="author-block" style="margin-top: 5px;font-size:1.4rem">
              <strong>arXiv 2026</strong>
            </span>
          </div>

          <div class="column has-text-centered" style="margin-top: 12px;">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf" style="font-size:21px"></i>
                  </span>
                  <span>Paper (Soon)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv" style="font-size:23px"></i>
                  </span>
                  <span>arXiv (Soon)</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github" style="font-size:23px"></i>
                  </span>
                  <span>Code (Soon)</span>
                </a>
              </span>
              <!-- Hugging Face Space (LCM). -->
              <span class="link-block">
                <a href="https://huggingface.co" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon" style="font-size:23px">
                      &#129303;
                  </span>
                  <span>Demo (Soon)</span>
                </a>
              </span>
              <!-- YouTube Playlist. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=U1eAGF_jcxI&list=PLIfXMX0d4BSJO_S3Wte7SAZpcdSFmZEvD" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-youtube" style="font-size:24px"></i>
                  </span>
                  <span>&nbsp;Gallery (5-30min Videos)</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  .rs-thumb {
    border-radius: 5px;
    overflow: hidden;
    background: #000;
    aspect-ratio: 16 / 9;
    width: 100%;
    height: auto;
  }
  .rs-thumb video {
    width: 100%;
    height: 100%;
    object-fit: cover;
    display: block;
  }
  .rs-cap{
    text-align: center;
    font-size: 1.0rem;
    margin-bottom: -10px;
  }
</style>

<section class="section" id="Teaser_and_QC" style="margin-top: -80px;">
  <div class="container is-max-desktop content is-centered has-text-centered">

    <!-- Row 1: YouTube full width -->
    <div class="columns is-variable is-2 is-centered">
      <div class="column is-max-desktop is-12-tablet">
        <div class="rs-thumb">
          <video controls autoplay muted loop playsinline preload="metadata">
            <source src="./videos/Ours_SnowBoard_YouTube.mp4" type="video/mp4">
          </video>
        </div>
        <p class="rs-cap">
          <strong class="rolling-sink-2">Rolling Sink</strong>
          <strong>(Ours)</strong>
          <br>
          Training duration: <strong>5s</strong> (FPS=16, here and below)
          <br>
          Testing duration: <strong>5min</strong>
        </p>
      </div>
    </div>

    <!-- Row 2: three mp4 across -->
    <div class="columns is-variable is-2 is-centered">
      <div class="column is-one-third-desktop is-12-tablet">
        <div class="rs-thumb">
          <video controls autoplay muted loop playsinline preload="metadata">
            <source src="./videos/SF_SnowBoard.mp4" type="video/mp4">
          </video>
        </div>
        <p class="rs-cap">
          <strong>Self Forcing</strong>
          <br>
          Training duration: <strong>5s</strong>
          <br>
          Testing duration: <strong>1min</strong>  
        </p>
      </div>

      <div class="column is-one-third-desktop is-12-tablet">
        <div class="rs-thumb">
          <video controls autoplay muted loop playsinline preload="metadata">
            <source src="./videos/LL_SnowBoard.mp4" type="video/mp4">
          </video>
        </div>
        <p class="rs-cap">
          <strong>LongLive (w/o LoRA)</strong>
          <br>
          Training duration: <strong>5s</strong>
          <br>
          Testing duration: <strong>1min</strong>        
        </p>
      </div>

      <div class="column is-one-third-desktop is-12-tablet">
        <div class="rs-thumb">
          <video controls autoplay muted loop playsinline preload="metadata">
            <source src="./videos/LL_LoRA_SnowBoard.mp4" type="video/mp4">
          </video>
        </div>
        <p class="rs-cap">
          <strong>LongLive (w/ LoRA)</strong>
          <br>
          Training duration: <strong>1min</strong>
          <br>
          Testing duration: <strong>2min</strong>
        </p>
      </div>
    </div>

  </div>
</section>

<section class="section hero is-light" id="Abstract" style="margin-top: -20px;">
  <div class="container is-max-desktop content is-centered has-text-centered">
    <h2 class="title is-3">Abstract</h2>
    <div class="content has-text-justified">
    <p>
      Recently, autoregressive (AR) video diffusion models has achieved remarkable performance.
      However, due to their limited training durations a train-test gap emerges when testing at longer horizons, leading to rapid visual degradations.
    </p><p>
      Following Self Forcing, which studies the train-test gap <strong>within</strong> the training duration, this work studies the train-test gap <strong>beyond</strong> the training duration, i.e., the gap between the limited horizons during training and open-ended horizons during testing.
    <!-- </p><p> -->
      Since open-ended testing can extend far beyond any finite training window, and long-video training is computationally expensive, we pursue a training-free solution to bridge this gap.
    </p><p>
      To explore a training-free solution, we conduct a systematic analysis of AR cache maintenance. These insights lead to <strong class="rolling-sink-2">Rolling Sink</strong>.
      Built on Self Forcing (trained on only 5s clips), Rolling Sink effectively scales the AR video synthesis to ultra-long durations (e.g., 5-30 minutes at 16 FPS) at test time, with consistent subjects, stable colors, coherent structures, and smooth motions.
      As demonstrated by extensive experiments, Rolling Sink achieves superior long-horizon visual fidelity and temporal consistency compared to SOTA baselines.
    </p>
    </div>
  </div>
</section>

<section class="section hero" id="Motivation" style="margin-top: -20px;">
  <div class="container is-max-desktop content is-centered has-text-centered">
    <h2 class="title is-3 has-text-centered">Motivation</h2>
    <div class="content has-text-justified">
      <p>
        Generating a long video (e.g., a movie) typically requires <strong>multi-shots</strong> input, i.e., a sequence of prompts.
        Each shot typically corresponds to a single prompt, and can vary from few seconds to minutes, even hours long.
        For instance, Steve McQueen's <a href="https://en.wikipedia.org/wiki/Hunger_(2008_film)">Hunger</a> begins with a classic 16.5 minutes dialogue shot (<a href="https://www.youtube.com/watch?v=aycGYu_8Hhw">YouTube link</a>, from <a href="https://youtu.be/aycGYu_8Hhw?si=FtKPoc_G5tkE1NU_&t=60">1:00</a> to <a href="https://youtu.be/aycGYu_8Hhw?si=NKrp7uH6VbYd7-Z7&t=1050">17:30</a>) between Bobby Sands and the priest.
        This motivates <strong>open-ended</strong> video generation.
      </p>
    </div>
    <div class="columns has-text-justified">
      <div class="column is-5">
        <p>
          Though large video diffusion models (e.g., 
          <a href="https://openai.com/index/sora-2/">Sora</a>,
          <a href="https://wan.video/">Wan</a>,
          <a href="https://app.klingai.com/global/release-notes/c605hp1tzd">Kling</a>,
          <a href="https://deepmind.google/models/veo/">Veo</a>,
          <a href="https://runwayml.com/research/introducing-runway-gen-4.5">Gen</a>) 
          have achieved remarkable performance, they usually denoise all frames simultaneously, making them <strong>incompatible</strong> with such open-ended setting.
          In contrast, autoregressive (AR) video diffusion models <strong>architecturally</strong> enables open-ended video generation by continuously predicting the <strong>next-frame</strong> conditioned on previous ones.
        </p>
        <p>
          However, AR video diffusion models are typically trained on limited and fixed durations (e.g., 5s at 16 FPS in <a href="https://self-forcing.github.io/">Self Forcing</a>).
          When extrapolating to long horizons, especially beyond the training duration, these models often suffer from rapid visual degradation.
        </p>
        <p>
          Such AR drift is commonly attributed to error accumulation.
          We further interpret it as a train-test gap between the <strong>limited-horizon training</strong> and <strong>open-ended testing</strong>.
        </p>
      </div>
      <div class="column is-7">
        <img src="./images/motivation.png">
      </div>
    </div>
  </div>
</section>

<section class="section hero" id="Methodology" style="margin-top: -20px;">
  <div class="container is-max-desktop content is-centered has-text-centered">
    <h2 class="title is-3">Methodology</h2>
    <div class="content has-text-justified">
    <p>
      Indeed, training on longer videos can mitigate this gap.
      However, as long as the training is conducted on <strong>finite-length</strong> clips, the open-ended testing can always exceed the training window.
      As the rollout length grows beyond this window, long-horizon drift can still occur.
      This motivates a <strong>training-free</strong> approach to bridge limited-horizon training and open-ended testing.
      The goal is to constantly reproduce the impressive video synthesis quality, exhibited when testing within the training duration, over ultra-long horizons.
    </p>
    <p>
      Since the prompt embedding stays <strong>fixed</strong> throughout AR video synthesis, and the initial noise for each block is always drawn from the <strong>same</strong> Gaussian distribution, the <strong>context (i.e., cache)</strong> is the major factor of long-horizon AR drift.
      Thus, for maintaining drift-free during open-ended testing, the AR cache should stay consistent with its <strong>within-duration</strong> behavior/characteristic.
    </p>
    </div>
  </div>
</section>

<section class="section hero" id="Experiments" style="margin-top: -20px;">
  <div class="container is-max-desktop content is-centered has-text-centered">
    <h2 class="title is-3">Experiments</h2>
    <div class="columns has-text-justified">
      <div class="column is-6">
        <p>
          Quantitative comparison of
          <strong class="rolling-sink-2">Rolling Sink</strong>
          with SOTA baselines on <strong>1-minute</strong> AR video synthesis using <a href="https://github.com/Vchitect/VBench/tree/master/vbench2_beta_long">VBench-Long</a>.
        </p>
        <img src="./images/qc_1min.png">
      </div>
      <div class="column is-6">
        <p>
          Quantitative comparison on <strong>5-minute</strong> AR video synthesis.
          <br>
          &nbsp;
        </p>
        <img src="./images/qc_5min.png">
      </div>
    </div>
    <div class="columns has-text-justified">
      <img src="./images/qc_radar.png">
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p>
      Please consider citing our paper if you find it useful in your research :-)
    </p>
    <pre class="selectable"><code>COMING SOON...
</code></pre>
  </div>
</section>

<footer class="footer pt-0 pb-0">
  <div class="container is-max-desktop content">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-justified">
          <p>
            Website template based on
            <a href="https://lotus3d.github.io/">
            Lotus,
            </a>
            <a href="https://lotus-2.github.io/">
            Lotus-2,
            </a>
            and
            <a href="https://depth-any-in-any-dir.github.io/">
            DA<sup>2</sup>.
            </a>
            Licensed under
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
            CC-BY-SA-4.0.
            </a>
            <br>
            Copyright &copy; Haodong Li, 2026.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>